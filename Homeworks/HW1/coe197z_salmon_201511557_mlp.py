# -*- coding: utf-8 -*-
"""CoE197Z_Salmon_201511557_MLP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1foVkAPsjyXmC_0ngeYGG9FYiyDv6Jgdz
"""

# Library Imports
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np

from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout
from keras.utils import plot_model, to_categorical, np_utils
from keras.datasets import cifar10

# Load CIFAR10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Get RGB Equivalent
num_pixels = x_train.shape[1]*x_train.shape[2]*x_train.shape[3]
print(num_pixels)
# 3 (RGB) * 32 * 32

# Flatten data
x_train = x_train.reshape(-1, num_pixels).astype('float32')
x_test = x_test.reshape(-1, num_pixels).astype('float32')

# Convert to one-hot vector
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_class = y_train.shape[1]
print(num_class)

# Scaling
x_train = x_train/255
x_test = x_test/255

# Deep Learning Model: 3-layer MLP network 
model = Sequential()
# ---------- LAYERS ----------
# 1st MLP
model.add(Dense(512, activation = 'relu'))
model.add(Dropout(0.2))
# 2nd MLP
model.add(Dense(256, activation = 'relu'))
model.add(Dropout(0.25))
# 3rd MLP
model.add(Dense(10, activation = 'softmax'))

# Indicate the loss function and use SGD as optimizer
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# Feed the network with complete dataset (1 epoch) 100 times
# Batch size of SGD is 4
model.fit(x_train, y_train, epochs = 100, batch_size = 32)

# Print summary to double check the network
model.summary()

# Create a nice image of the network model
plot_model(model, to_file = 'linear-model.png', show_shapes = True)

# Print final accuracy
loss, acc = model.evaluate(x_test, y_test, batch_size = 32)
print("Test accuracy: %.2f%%" % (100 * acc))